{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reg_ready.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>monthly_return</th>\n",
       "      <th>period of downturn</th>\n",
       "      <th>Recessions</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>yc_date</th>\n",
       "      <th>YIELD_CURVE</th>\n",
       "      <th>UNEMPLOYMENT</th>\n",
       "      <th>BGI_diff_from_2_month_high</th>\n",
       "      <th>KO_diff_from_2_month_high</th>\n",
       "      <th>KR_diff_from_2_month_high</th>\n",
       "      <th>MAR_diff_from_2_month_high</th>\n",
       "      <th>PPG_diff_from_2_month_high</th>\n",
       "      <th>SHW_diff_from_2_month_high</th>\n",
       "      <th>unemployment_diff_from_6_month_low</th>\n",
       "      <th>INDPRO_diff_from_6_month_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362</td>\n",
       "      <td>1980-04-01</td>\n",
       "      <td>102.089996</td>\n",
       "      <td>106.290001</td>\n",
       "      <td>0.041140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.5053</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.041825</td>\n",
       "      <td>-0.053846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363</td>\n",
       "      <td>1980-05-01</td>\n",
       "      <td>106.290001</td>\n",
       "      <td>111.239998</td>\n",
       "      <td>0.046571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.3294</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>364</td>\n",
       "      <td>1980-06-01</td>\n",
       "      <td>111.239998</td>\n",
       "      <td>114.239998</td>\n",
       "      <td>0.026969</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.2336</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.068085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>365</td>\n",
       "      <td>1980-07-01</td>\n",
       "      <td>114.239998</td>\n",
       "      <td>121.669998</td>\n",
       "      <td>0.065039</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.9638</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366</td>\n",
       "      <td>1980-08-01</td>\n",
       "      <td>121.669998</td>\n",
       "      <td>122.379997</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.3348</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.1705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       Date        Open       Close  monthly_return  \\\n",
       "0    362 1980-04-01  102.089996  106.290001        0.041140   \n",
       "1    363 1980-05-01  106.290001  111.239998        0.046571   \n",
       "2    364 1980-06-01  111.239998  114.239998        0.026969   \n",
       "3    365 1980-07-01  114.239998  121.669998        0.065039   \n",
       "4    366 1980-08-01  121.669998  122.379997        0.005835   \n",
       "\n",
       "   period of downturn  Recessions   INDPRO     yc_date  YIELD_CURVE  \\\n",
       "0                   0           1  53.5053  2014-09-02         1.89   \n",
       "1                   0           1  53.3294  2014-09-02         1.89   \n",
       "2                   0           1  52.2336  2014-09-02         1.89   \n",
       "3                   0           1  50.9638  2014-09-02         1.89   \n",
       "4                   0           1  50.3348  2014-09-02         1.89   \n",
       "\n",
       "   UNEMPLOYMENT  BGI_diff_from_2_month_high  KO_diff_from_2_month_high  \\\n",
       "0           6.3                         NaN                  -0.041825   \n",
       "1           6.3                         NaN                   0.000000   \n",
       "2           6.9                         NaN                   0.000000   \n",
       "3           7.5                         NaN                  -0.022222   \n",
       "4           7.6                         NaN                   0.000000   \n",
       "\n",
       "   KR_diff_from_2_month_high  MAR_diff_from_2_month_high  \\\n",
       "0                  -0.053846                         NaN   \n",
       "1                   0.000000                         NaN   \n",
       "2                   0.000000                         NaN   \n",
       "3                   0.000000                         NaN   \n",
       "4                   0.000000                         NaN   \n",
       "\n",
       "   PPG_diff_from_2_month_high  SHW_diff_from_2_month_high  \\\n",
       "0                    0.000000                    0.000000   \n",
       "1                    0.000000                    0.000000   \n",
       "2                    0.000000                   -0.068085   \n",
       "3                   -0.008264                    0.000000   \n",
       "4                    0.000000                    0.000000   \n",
       "\n",
       "   unemployment_diff_from_6_month_low  INDPRO_diff_from_6_month_high  \n",
       "0                                 0.4                         0.0000  \n",
       "1                                 0.4                         0.1759  \n",
       "2                                 1.0                         1.2717  \n",
       "3                                 1.5                         2.5415  \n",
       "4                                 1.3                         3.1705  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REL_VARS = ['YIELD_CURVE','KO_diff_from_2_month_high',\n",
    "       'KR_diff_from_2_month_high',\n",
    "       'PPG_diff_from_2_month_high', 'SHW_diff_from_2_month_high',\n",
    "       'unemployment_diff_from_6_month_low', 'INDPRO_diff_from_6_month_high']\n",
    "\n",
    "\n",
    "\n",
    "df.dropna(subset=REL_VARS,inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create windows of proper dimension (samples X timesteps X features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y_downturn = []\n",
    "y_monthly_return = []\n",
    "\n",
    "for idx,dt in enumerate(df['Date']):\n",
    "    obs_prior = df[df['Date']<=dt].shape[0]\n",
    "    if obs_prior>=12:\n",
    "        sample = []\n",
    "        df_last_12 = df[df['Date']<=dt].iloc[-12:]\n",
    "        sample.append(list(df_last_12['YIELD_CURVE']))\n",
    "        sample.append(list(df_last_12['KO_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['KR_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['PPG_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['SHW_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['unemployment_diff_from_6_month_low']))\n",
    "        sample.append(list(df_last_12['INDPRO_diff_from_6_month_high']))\n",
    "        sample = np.array(sample).T\n",
    "        \n",
    "        X.append(sample)\n",
    "        y_downturn.append(df.iloc[idx]['period of downturn'])\n",
    "        y_monthly_return.append(df.iloc[idx]['monthly_return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 12, 7)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.array(X)\n",
    "arr1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 19)\n",
      "(177, 19)\n"
     ]
    }
   ],
   "source": [
    "df_train = df.iloc[11:296]\n",
    "print(df_train.shape)\n",
    "df_test = df.iloc[297:]\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with predicting monthly return on 1980 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_monthly_return)\n",
    "X = arr1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 12, 7)\n",
      "(177, 12, 7)\n"
     ]
    }
   ],
   "source": [
    "trainX = X[:285,:,:]\n",
    "trainY = y[:285]\n",
    "\n",
    "testX = X[286:,:,:]\n",
    "testY = y[286:]\n",
    "print(trainX.shape)\n",
    "print(testX.shape)  ##We can see that the dimensions of the numpy arrays are what we expected for merging with dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "features=7\n",
    "timesteps=12\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(LSTM(4, batch_input_shape=(batch_size, timesteps, features), return_sequences=True,activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LSTM(16, batch_input_shape=(batch_size, timesteps, features), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (1, 16)                   1536      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (1, 1)                    17        \n",
      "=================================================================\n",
      "Total params: 1,553\n",
      "Trainable params: 1,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 177 samples\n",
      "Epoch 1/12\n",
      " - 3s - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 2/12\n",
      " - 2s - loss: 0.0023 - val_loss: 0.0156\n",
      "Epoch 3/12\n",
      " - 2s - loss: 0.0022 - val_loss: 0.0115\n",
      "Epoch 4/12\n",
      " - 2s - loss: 0.0022 - val_loss: 0.0095\n",
      "Epoch 5/12\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0075\n",
      "Epoch 6/12\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0067\n",
      "Epoch 7/12\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 8/12\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 9/12\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 10/12\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 11/12\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 12/12\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0049\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(trainX, trainY, epochs=12, batch_size=batch_size, verbose=2, shuffle=False,validation_data=[testX,testY])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['pred'] = trainPredict\n",
    "df_train.to_csv('trainset_LSTM_1980.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['pred'] = testPredict\n",
    "df_test.to_csv('testset_LSTM_1980.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us try with downturn classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 12, 7)\n",
      "(177, 12, 7)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y_downturn)\n",
    "X = arr1.copy()\n",
    "\n",
    "trainX = X[:285,:,:]\n",
    "trainY = y[:285]\n",
    "\n",
    "testX = X[286:,:,:]\n",
    "testY = y[286:]\n",
    "print(trainX.shape)\n",
    "print(testX.shape)  ##We can see that the dimensions of the numpy arrays are what we expected for merging with dfs.\n",
    "\n",
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "features=7\n",
    "timesteps=12\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(LSTM(4, batch_input_shape=(batch_size, timesteps, features), return_sequences=True,activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(LSTM(16, batch_input_shape=(batch_size, timesteps, features), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 177 samples\n",
      "Epoch 1/7\n",
      " - 3s - loss: 0.5593 - val_loss: 0.4269\n",
      "Epoch 2/7\n",
      " - 2s - loss: 0.3878 - val_loss: 0.4186\n",
      "Epoch 3/7\n",
      " - 2s - loss: 1.1075 - val_loss: 1.2874\n",
      "Epoch 4/7\n",
      " - 2s - loss: 1.9794 - val_loss: 1.2874\n",
      "Epoch 5/7\n",
      " - 2s - loss: 1.9794 - val_loss: 1.2874\n",
      "Epoch 6/7\n",
      " - 2s - loss: 1.9794 - val_loss: 1.2874\n",
      "Epoch 7/7\n",
      " - 2s - loss: 1.9794 - val_loss: 1.2874\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(trainX, trainY, epochs=7, batch_size=batch_size, verbose=2, shuffle=False,validation_data=[testX,testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelholden/anaconda3/envs/dnn/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['pred'] = testPredict\n",
    "#df_test.to_csv('testset_LSTM_classification_1980.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try with fewer features - 1980, drop KO,KR, and monthly_return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 19)\n",
      "(177, 19)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y_downturn = []\n",
    "y_monthly_return = []\n",
    "\n",
    "for idx,dt in enumerate(df['Date']):\n",
    "    obs_prior = df[df['Date']<=dt].shape[0]\n",
    "    if obs_prior>=12:\n",
    "        sample = []\n",
    "        df_last_12 = df[df['Date']<=dt].iloc[-12:]\n",
    "        sample.append(list(df_last_12['YIELD_CURVE']))\n",
    "        #sample.append(list(df_last_12['KO_diff_from_2_month_high']))\n",
    "        #sample.append(list(df_last_12['KR_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['PPG_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['SHW_diff_from_2_month_high']))\n",
    "        sample.append(list(df_last_12['unemployment_diff_from_6_month_low']))\n",
    "        sample.append(list(df_last_12['INDPRO_diff_from_6_month_high']))\n",
    "        sample = np.array(sample).T\n",
    "        \n",
    "        X.append(sample)\n",
    "        y_downturn.append(df.iloc[idx]['period of downturn'])\n",
    "        y_monthly_return.append(df.iloc[idx]['monthly_return'])\n",
    "        \n",
    "arr1 = np.array(X)\n",
    "arr1.shape\n",
    "\n",
    "df_train = df.iloc[11:296]\n",
    "print(df_train.shape)\n",
    "df_test = df.iloc[297:]\n",
    "print(df_test.shape)\n",
    "\n",
    "y = np.array(y_monthly_return)\n",
    "X = arr1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, 12, 5)\n",
      "(177, 12, 5)\n"
     ]
    }
   ],
   "source": [
    "trainX = X[:285,:,:]\n",
    "trainY = y[:285]\n",
    "\n",
    "testX = X[286:,:,:]\n",
    "testY = y[286:]\n",
    "print(trainX.shape)\n",
    "print(testX.shape)  ##We can see that the dimensions of the numpy arrays are what we expected for merging with dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "batch_size = 1\n",
    "features=5\n",
    "timesteps=12\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(16, batch_input_shape=(batch_size, timesteps, features), activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 177 samples\n",
      "Epoch 1/15\n",
      " - 3s - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 2/15\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 3/15\n",
      " - 2s - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 4/15\n",
      " - 2s - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 5/15\n",
      " - 2s - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 6/15\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 7/15\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 8/15\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 9/15\n",
      " - 2s - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 10/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0074\n",
      "Epoch 11/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0063\n",
      "Epoch 12/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0081\n",
      "Epoch 13/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0094\n",
      "Epoch 14/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0174\n",
      "Epoch 15/15\n",
      " - 2s - loss: 0.0020 - val_loss: 0.0124\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(trainX, trainY, epochs=15, batch_size=batch_size, verbose=2, shuffle=False,validation_data=[testX,testY])\n",
    "\n",
    "#trainPredict = model.predict(trainX, batch_size=batch_size)\n",
    "#df_train['pred'] = trainPredict\n",
    "#df_train.to_csv('trainset_LSTM_1980_reducedfeats.csv',index=False)\n",
    "#\n",
    "#testPredict = model.predict(testX, batch_size=batch_size)\n",
    "#df_test['pred'] = testPredict\n",
    "#df_test.to_csv('testset_LSTM_1980_reducedfeats.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So the 1980 full features is the best (or equivalent) of the RNN models tried. Let's comment out the extra to simplify file mgmt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not better (although more sensitive) than classification RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
